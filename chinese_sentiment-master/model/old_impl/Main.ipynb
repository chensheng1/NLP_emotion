{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jieba\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入词向量\n",
    "cn_word_vecs = KeyedVectors.load_word2vec_format(\n",
    "    'sgns.zhihu.bigram', binary=False)\n",
    "ebd_dim = cn_word_vecs[u'我'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS = os.path.join(os.getcwd(), 'fix_pos')\n",
    "NEG = os.path.join(os.getcwd(), 'fix_neg')\n",
    "\n",
    "# 存储所有评价，每例评价为一条string\n",
    "train_text_raw = []\n",
    "for file_name in os.listdir(POS):\n",
    "    with open(os.path.join(POS, file_name), 'r') as f:\n",
    "        train_text_raw.append(f.read().strip().decode('utf-8'))\n",
    "\n",
    "for file_name in os.listdir(NEG):\n",
    "    with open(os.path.join(NEG, file_name), 'r') as f:\n",
    "        train_text_raw.append(f.read().strip().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "由于, 火车, 时间, 不得不, 在, 早上, 六点, 到, 酒店, 等到, 快, 八点, 才, 入住, 好惨, 通过, 携程, 预订, 标明, 是, 双早, 却, 给, 了, 一张, 早餐, 卷券害, 得, 要, 回, 房间, 吃, 方便面, 房间, 宽带, 总是, 断, 不过, 环境, 真是, 不错\n",
      "[491, 2241, 139, 1569, 15, 1001, 0, 48, 1845, 2374, 488, 0, 126, 11780, 41456, 259, 14862, 21262, 20155, 4, 0, 141, 51, 3, 0, 4656, 0, 117, 20, 494, 1487, 116, 7998, 1487, 22380, 412, 2066, 223, 578, 418, 562]\n",
      "--------------------------------------------------------------------------------\n",
      "在, 南山区, 办事, 的话, 住, 这里, 还, 算, 方便, 门口, 往, 哪个, 方向, 的, 车, 都, 有, 就是, 稍微, 有点, 吵, 啊\n",
      "[15, 122427, 6474, 425, 659, 307, 40, 640, 1419, 1235, 478, 884, 974, 1, 356, 11, 8, 25, 1532, 348, 5020, 90]\n",
      "--------------------------------------------------------------------------------\n",
      "第二次, 住, 的, 时候, 酒店, 说, 我, 在, 房间, 里, 消费, 很, 冤枉\n",
      "[0, 659, 1, 43, 1845, 16, 6, 15, 1487, 63, 1622, 34, 12374]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# train_tokens是一个长长的list，其中含有4000个小list，对应每一条评价\n",
    "train_tokens = []\n",
    "word_lists = []\n",
    "pattern = ur\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\"\n",
    "for text in train_text_raw:\n",
    "    p_text = re.sub(pattern, \"\", text)\n",
    "    cut = jieba.cut(p_text)\n",
    "    cut_list = []\n",
    "    word_list = []\n",
    "    for word in cut:\n",
    "        word_list.append(word)\n",
    "        try:\n",
    "            cut_list.append(cn_word_vecs.vocab[word].index)\n",
    "        except KeyError:\n",
    "            cut_list.append(0)\n",
    "    train_tokens.append(cut_list)\n",
    "    word_lists.append(word_list)\n",
    "    \n",
    "# 打印一些tokenize后的样本\n",
    "samples = random.sample(range(len(train_tokens)), 3)\n",
    "for i in samples:\n",
    "    print u\", \".join(word_lists[i])\n",
    "    print train_tokens[i]\n",
    "    print '-'*80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均长度为 71.458750\n",
      "最长的评论长度为 1540\n"
     ]
    }
   ],
   "source": [
    "num_tokens = np.array([len(tokens) for tokens in train_tokens])\n",
    "print '平均长度为 %f' % np.mean(num_tokens)\n",
    "print '最长的评论长度为 %d' % np.max(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log(num_tokens), bins = 100)\n",
    "plt.xlim((0,10))\n",
    "plt.ylabel('number of tokens')\n",
    "plt.xlabel('length of tokens')\n",
    "plt.title('Distribution of tokens length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取tokens平均值并加上两个tokens的标准差，\n",
    "# 假设tokens长度的分布为正态分布，则max_tokens这个值可以涵盖95%左右的样本\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用来将tokens转换为文本\n",
    "def reverse_tokens(tokens):\n",
    "    text = ''\n",
    "    for i in tokens:\n",
    "        if i != 0:\n",
    "            text = text + cn_word_vecs.index2word[i]\n",
    "        else:\n",
    "            text = text + ' '\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "房间每天都有免费水果赠送这一点比较好还有好多书籍和摄影著作摆在房间里据说都是合庆董事长自己编写拍摄的太有才了\n",
      "看了前面的点评感觉此酒店应该不错所以这次去慈溪定了国脉酒店结果大失所望酒店位置不错298的大床房窗外景色好公园小街不满意的地方：一房间 地毯肯定 未洗污渍满地如果像走道一样铺大理石反而干净得多；椅背床背都不干净房间居然还有一个大苍蝇；二洗澡的花洒非常不好用三大堂的灯太昏暗头晕四前台的服务小姐态度比较生硬；五酒店所有的商务单人大床 但是低下是冷却塔厨房烟道比较嘈\n"
     ]
    }
   ],
   "source": [
    "print reverse_tokens(train_tokens[100])\n",
    "print reverse_tokens(train_tokens[2200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Embedding, LSTM, Dropout\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 50001\n",
    "ebd_matrix = np.zeros((num_words, ebd_dim))\n",
    "for i in range(num_words):\n",
    "    ebd_matrix[i,:] = cn_word_vecs[cn_word_vecs.index2word[i]]\n",
    "ebd_matrix = ebd_matrix.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理缺失数据\n",
    "\n",
    "# 方式1， 截断长序列的前面部分，在短序列前面部分补0 测试集accuracy 84%\n",
    "# train_pad = pad_sequences(train_tokens, maxlen=max_tokens,\n",
    "#                             padding='pre', truncating='pre')\n",
    "# train_pad[ train_pad>=num_words ] = 0\n",
    "\n",
    "# 方式2， 截断长序列的后面部分，在短序列后面部分补0 测试集accuracy 88%\n",
    "train_pad = pad_sequences(train_tokens, maxlen=max_tokens,\n",
    "                            padding='post', truncating='post')\n",
    "train_pad[ train_pad>=num_words ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = np.concatenate((np.ones(2000),np.zeros(2000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_pad,\n",
    "                                                    train_target,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "住的是 房房间超大环境一流价钱不算高258 2早 是服务有点跟不上总体不错                                                                                                                                                                                                                     \n",
      "class: %d 1.0\n"
     ]
    }
   ],
   "source": [
    "print reverse_tokens(x_train[100])\n",
    "print 'class: %d', y_train[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 236, 300)          15000300  \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 16)                20288     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,020,605\n",
      "Trainable params: 20,305\n",
      "Non-trainable params: 15,000,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# 第一层 embeding\n",
    "model.add(Embedding(num_words,\n",
    "                    ebd_dim,\n",
    "                    weights=[ebd_matrix],\n",
    "                    input_length=max_tokens,\n",
    "                    mask_zero=True,\n",
    "                    trainable=False))\n",
    "#model.add(LSTM(units=32, return_sequences=True))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(LSTM(units=16, return_sequences=False))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "optimizer = Adam(lr=1e-3)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义early stoping如果3个epoch内validation loss没有改善则停止训练\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)\n",
    "\n",
    "# 自动降低learning rate\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                       factor=0.1, min_lr=1e-5, patience=0,\n",
    "                                       verbose=1)\n",
    "# 定义callback函数\n",
    "callbacks = [\n",
    "    earlystopping, \n",
    "    lr_reduction\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3240 samples, validate on 360 samples\n",
      "Epoch 1/20\n",
      "3240/3240 [==============================] - 5s 1ms/step - loss: 0.6536 - acc: 0.6194 - val_loss: 0.6072 - val_acc: 0.7028\n",
      "Epoch 2/20\n",
      "3240/3240 [==============================] - 4s 1ms/step - loss: 0.5153 - acc: 0.7580 - val_loss: 0.4313 - val_acc: 0.8278\n",
      "Epoch 3/20\n",
      "3240/3240 [==============================] - 4s 1ms/step - loss: 0.3908 - acc: 0.8373 - val_loss: 0.3484 - val_acc: 0.8639\n",
      "Epoch 4/20\n",
      "3240/3240 [==============================] - 4s 1ms/step - loss: 0.3383 - acc: 0.8645 - val_loss: 0.3275 - val_acc: 0.8639\n",
      "Epoch 5/20\n",
      "3240/3240 [==============================] - 4s 1ms/step - loss: 0.3134 - acc: 0.8716 - val_loss: 0.3143 - val_acc: 0.8861\n",
      "Epoch 6/20\n",
      "3240/3240 [==============================] - 4s 1ms/step - loss: 0.2767 - acc: 0.8935 - val_loss: 0.3063 - val_acc: 0.8722\n",
      "Epoch 7/20\n",
      "3240/3240 [==============================] - 4s 1ms/step - loss: 0.2647 - acc: 0.8975 - val_loss: 0.2978 - val_acc: 0.8778\n",
      "Epoch 8/20\n",
      "3240/3240 [==============================] - 4s 1ms/step - loss: 0.2365 - acc: 0.9099 - val_loss: 0.2957 - val_acc: 0.8750\n",
      "Epoch 9/20\n",
      "3240/3240 [==============================] - 4s 1ms/step - loss: 0.2150 - acc: 0.9219 - val_loss: 0.2751 - val_acc: 0.8972\n",
      "Epoch 10/20\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.2035 - acc: 0.9219\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000475.\n",
      "3240/3240 [==============================] - 4s 1ms/step - loss: 0.2016 - acc: 0.9228 - val_loss: 0.2989 - val_acc: 0.8778\n",
      "Epoch 11/20\n",
      "3240/3240 [==============================] - 4s 1ms/step - loss: 0.1851 - acc: 0.9324 - val_loss: 0.2668 - val_acc: 0.8944\n",
      "Epoch 12/20\n",
      "3240/3240 [==============================] - 4s 1ms/step - loss: 0.1770 - acc: 0.9358 - val_loss: 0.2616 - val_acc: 0.9000\n",
      "Epoch 13/20\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.1736 - acc: 0.9394\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000000475e-05.\n",
      "3240/3240 [==============================] - 4s 1ms/step - loss: 0.1742 - acc: 0.9392 - val_loss: 0.2622 - val_acc: 0.9000\n",
      "Epoch 14/20\n",
      "3200/3240 [============================>.] - ETA: 0s - loss: 0.1714 - acc: 0.9394\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "3240/3240 [==============================] - 4s 1ms/step - loss: 0.1719 - acc: 0.9395 - val_loss: 0.2630 - val_acc: 0.9000\n",
      "Epoch 15/20\n",
      "3240/3240 [==============================] - 4s 1ms/step - loss: 0.1716 - acc: 0.9392 - val_loss: 0.2632 - val_acc: 0.9000\n",
      "Epoch 00015: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0702bddc10>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 开始训练\n",
    "model.fit(x_train, y_train,\n",
    "          validation_split=0.1, \n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 0s 1ms/step\n",
      "Accuracy:0.880000\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(x_test, y_test)\n",
    "print 'Accuracy:%f'%result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    print text\n",
    "    p_text = re.sub(pattern, \"\", text)\n",
    "    cut = jieba.cut(p_text)\n",
    "    cut_list = []\n",
    "    for word in cut:\n",
    "        try:\n",
    "            cut_list.append(cn_word_vecs.vocab[word].index)\n",
    "        except KeyError:\n",
    "            cut_list.append(0)\n",
    "    tokens_pad = pad_sequences([cut_list], maxlen=max_tokens,\n",
    "                           padding='pre', truncating='pre')\n",
    "    tokens_pad[ tokens_pad>=num_words ] = 0\n",
    "    result = model.predict(x=tokens_pad)\n",
    "    coef = result[0][0]\n",
    "    if coef >= 0.5:\n",
    "        print '是一例正面评价','output=%.2f'%coef\n",
    "    else:\n",
    "        print '是一例负面评价','output=%.2f'%coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "酒店设施不是新的，服务态度很不好\n",
      "是一例负面评价 output=0.33\n",
      "酒店卫生条件非常不好\n",
      "是一例负面评价 output=0.09\n",
      "床铺非常舒适\n",
      "是一例正面评价 output=0.82\n",
      "房间很凉，不给开暖气\n",
      "是一例负面评价 output=0.26\n",
      "房间很凉爽，空调冷气很足\n",
      "是一例正面评价 output=0.65\n",
      "酒店环境不好，住宿体验很不好\n",
      "是一例负面评价 output=0.08\n",
      "房间隔音不到位\n",
      "是一例负面评价 output=0.18\n",
      "晚上回来发现没有打扫卫生\n",
      "是一例负面评价 output=0.23\n",
      "因为过节所以要我临时加钱，比团购的价格贵\n",
      "是一例负面评价 output=0.07\n"
     ]
    }
   ],
   "source": [
    "test_list = [\n",
    "    '酒店设施不是新的，服务态度很不好',\n",
    "    '酒店卫生条件非常不好',\n",
    "    '床铺非常舒适',\n",
    "    '房间很凉，不给开暖气',\n",
    "    '房间很凉爽，空调冷气很足',\n",
    "    '酒店环境不好，住宿体验很不好',\n",
    "    '房间隔音不到位' ,\n",
    "    '晚上回来发现没有打扫卫生',\n",
    "    '因为过节所以要我临时加钱，比团购的价格贵'\n",
    "]\n",
    "for text in test_list:\n",
    "    predict_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tfenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
